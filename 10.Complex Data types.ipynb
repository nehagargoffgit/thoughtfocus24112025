{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16c26405-7524-4b88-a10b-efe3d8062f94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eb6f9c9-f182-4e21-86c4-e294930ad129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(path=\"/Volumes/quickstart_catalog/quickstart_schema/sandbox/dataset/employee.csv\",\n",
    "                    sep=\"|\",\n",
    "                    inferSchema=True,\n",
    "                    header=True,\n",
    "                    quote=\"'\").limit(10)\n",
    "display(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1803d9f0-dd9b-459a-86ab-a16f5a700b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d845097-a6f8-4986-b273-f7575f8727e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Array Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59614516-d422-42e7-9107-e2d3f1f11091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Create an Arrary Type of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4becf3f-83ce-4e92-88e8-51e5dc96b970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "#result_df = df.withColumn(\"skill\",split(\"col_skills\",\",\").withColumn(\"Expected_salary\",split(\"col_current_expected_salary\",\",\").cast# #(\"array<int>\"),)\n",
    "result_df = (\n",
    "    df.withColumn(\"skills\", split(\"col_skills\", \",\"))\n",
    "    .withColumn(\n",
    "        \"current_expected_salary\",\n",
    "        split(\"col_current_expected_salary\", \",\").cast(\"array<int>\"),\n",
    "    )\n",
    "    .drop(\"col_skills\", \"col_current_expected_salary\")\n",
    ")\n",
    "result_df.printSchema()\n",
    "result_df.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cac3fb49-3584-4173-a659-24e0ac97f443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2288dfc-442a-4424-a7a9-fa9d315a6550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "result_df = df.withColumn(\"Expected_salary\",split(\"col_current_expected_salary\",\",\").cast(\"array<int>\"),)\n",
    "result_df.printSchema()\n",
    "result_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19509f71-24f8-4416-9293-53ebef5b38f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "#result_df = df.withColumn(\"skill\",split(\"col_skills\",\",\").withColumn(\"Expected_salary\",split(\"col_current_expected_salary\",\",\").cast# #(\"array<int>\"),)\n",
    "result_df = (\n",
    "    df.withColumn(\"skills\", split(\"col_skills\", \",\"))\n",
    "    .withColumn(\n",
    "        \"current_expected_salary\",\n",
    "        split(\"col_current_expected_salary\", \",\").cast(\"array<int>\"),\n",
    "    )\n",
    "    .drop(\"col_skills\", \"col_current_expected_salary\")\n",
    ")\n",
    "result_df.printSchema()\n",
    "result_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1776fa3-d0e5-4206-a86f-00c464350408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###ways to Access array col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66776cc3-5db3-4d43-a2e9-f865d7369eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "result_df.select(col(\"skills\"),col(\"skills\").getItem(0),col(\"skills\")[0]).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56e5b072-cf03-4fae-87ce-97d33a399426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Problem Statement\n",
    "> Derive 2 new columns 1 is 'current salary' and 'Ã©xpected salary' from 'current_expected_salary' frm array column\n",
    "\n",
    "1. First column is current salary\n",
    "2. 2nd is expected salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2eaa3c9-d37d-4d54-b7a5-2f0ee4398218",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "result_df.select(\n",
    "    col(\"current_expected_salary\"),\n",
    "    col(\"current_expected_salary\")[0].alias(\"current_salary\"),\n",
    "    col(\"current_expected_salary\")[1].alias(\"expected_salary\"),\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f741a986-328d-4fd1-967d-dafeee7a619e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Problem\n",
    "Fetch employee names whose current_salary is greater than expected_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b5ed23a-ab42-4c65-a589-96301f8f81d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df.filter(\n",
    "    col(\"current_expected_salary\")[0] > col(\"current_expected_salary\")[1]\n",
    ").select(col(\"name\")).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8265d7aa-cfaa-4068-9003-2b096f360d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##ARRAY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91f5d01b-2be9-4e7f-92f6-adf9c79506de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size, array_distinct, array_contains,col\n",
    " \n",
    "result_df.select(\n",
    "    col(\"name\"),\n",
    "    col(\"skills\"),\n",
    "    size(\"skills\"), # gives no of elements\n",
    "    array_contains(\"skills\", \"PySpark\"), # gives array value contains or not\n",
    "    array_distinct(\"skills\").alias(\"distinct_skills\"), # Distinct \n",
    ").display() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dee00a3-4162-43b0-a81b-79e862a61ed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df.filter(array_contains(\"skills\", \"PySpark\")).select(\n",
    "    col(\"name\"),\n",
    "    col(\"skills\"),\n",
    ").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bce4922-77e1-4a07-92be-da14827ee58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df.filter(col(\"skills\").when array_contains(\"skills\", \"PySpark\") THEN\n",
    "         df.withColumn(\"skills\", split(\"col_skills\", \",\"))           \n",
    "select(\n",
    "    col(\"name\"),\n",
    "    col(\"skills\"),\n",
    "    col(\"current_expected_salary\"),\n",
    "    array_contains(\"skills\", \"PySpark\"), \n",
    ").display() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5923bf89-159a-4e3a-b669-0f62b2aba1ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "result_df_new = (\n",
    "    result_df.withColumn(\"base_salary\", col(\"current_expected_salary\")[0])\n",
    "    )\n",
    "#result_df_new.printSchema()\n",
    "result_df_new.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee6d77e-3676-4ec9-b4f9-4815218f9d1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains, col\n",
    " \n",
    "result_df.withColumn(\n",
    "    \"base_salary\",\n",
    "    when(\n",
    "        array_contains(\"skills\", \"PySpark\"), (col(\"current_expected_salary\")[1] * 1.3).cast(\"decimal(18,2)\")\n",
    "    ).otherwise(col(\"current_expected_salary\")[1]),\n",
    ").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "311c9165-08fa-4d16-a5b1-53a5756a0647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "result_df.select(explode(\"skills\").alias(\"words\")).groupBy(\"words\").count().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4c71a63-401f-4979-bd75-f131620d7d20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Struct Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589c39fc-c671-4db8-a8cd-0915f3e8d6e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(path=\"/Volumes/quickstart_catalog/quickstart_schema/sandbox/dataset/product_Information_001.json\",\n",
    "                   multiLine=True,)\n",
    "display(df) \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5726ef79-e2dd-47f0-9c99-83f673947f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"name\"),col(\"details.screen.size\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "273aad74-456b-4f08-b3f0-b55e19a0d899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"name\"),col(\"details.storage.capacity\")).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10.Complex Data types",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
